{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Reptilia Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Commands\n",
    "\n",
    "Key:\n",
    "\"*\" = Done\n",
    "\"**\" = In progress\n",
    "\n",
    "\n",
    "File Name Notes:\n",
    "- All Gamma (-mG models) have _G in the file name\n",
    "- Gibbs models have Gibbs in the name\n",
    "\n",
    "First date = when .pkl and sum.txt are outputted\n",
    "Second date = when ex_rates, sp_rates, per_species_rates, mcmc are ouptutted \n",
    "\n",
    "CoVar Model (not BDNN): 8/15, 8/19\n",
    "- *python PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -trait_file data/reptilia/Reptilia_species_traits.txt -mCov 5 -logT 1 -pC 0 -fixShift data/Time_bins_CrossStage.txt -qShift data/Time_bins_ByStages.txt -mG -A 0 -n 20000000 -s 2000\n",
    "    - This is: a Covar BD model with fixed times of rate shifts, log transformed traits, TPP and Gamma preservation model, parameter estimation MCMC\n",
    "\n",
    "BDNN run 1: 8/15, 8/19\n",
    "- *python PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -j 1 -fixShift data/Time_bins_CrossStage.txt -BDNNmodel 1 -trait_file data/reptilia/Reptilia_species_traits.txt -qShift data/Time_bins_ByStages.txt -mG -A 0 -n 20000000 -s 2000\n",
    "    - Traits file needed to be: normalized continuous variables, no nulls, consistent data types, tab separated .txt\n",
    "\n",
    "BDNN run 2: 8/27, 8/28\n",
    "- *python PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -j 1 -fixShift data/Time_bins_ByStages.txt -BDNNmodel 1 -trait_file data/reptilia/Reptilia_species_traits.txt -qShift data/Time_bins_ByStages.txt -A 0 -n 20000000 -s 2000 -BDNNnodes 8 4 -BDNNupdate_f 0.05 0.05 0.25 -singleton 1\n",
    "    - Removed -mG flag\n",
    "    - Removed singletons using -singleton 1\n",
    "    - Reduced network complexity:\n",
    "        - -BDNNnodes 8 4\n",
    "        - -BDNNupdate_f 0.05 0.05 0.25\n",
    "    - Shifted dates towards the present to remove empty space from LAD to present day: -translate 175.0\n",
    "\n",
    "BDNN run 3: Torsten Reduced Complexity + no -mG, 8/28, 8/29, 8/30. 9/4\n",
    "- *python ../PyRate/PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -j 1 -fixShift data/Time_bins_CrossStage.txt -BDNNmodel 1 -trait_file data/reptilia/Reptilia_species_traits.txt -qShift data/Time_bins_CrossStage.txt -n 50000000 -s 50000 -BDNNnodes 8 4 -translate -175\n",
    "    - **Result**: low ESS prior, BD_lik. Burn-in ~ 15%\n",
    "- *python ../PyRate/PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -j 1 -fixShift data/Time_bins_ByStages.txt -BDNNmodel 1 -trait_file data/reptilia/Reptilia_species_traits.txt -qShift data/Time_bins_ByStages.txt -n 50000000 -s 50000 -BDNNnodes 8 4 -translate -175\n",
    "    - Starting to use PyRate from PyRate repo, not Arielli repo\n",
    "    - Removed -mG flag\n",
    "    - Reduced network complexity: -BDNNnodes 8 4\n",
    "    - **Result**: low ESS prior, BD_lik. Burn-in very high for those two. Going forward with 10%\n",
    "BDNN run 3 RESTORED:\n",
    "- python PyRate.py ../PyRate/PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -restore_mcmc ..../pyrate_mcmc_logs/*_mcmc.log -BDNNmodel 1 -trait_file  .../Traits.txt -BDNNtimevar …/Paleotemperature.txt -mG -n 200001 -p 20000 -s 5000\n",
    "\n",
    "\n",
    "BDNN run 4: Gibbs + no -mG\n",
    "- **python ../PyRate/PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -j 1 -fixShift data/Time_bins_CrossStage.txt -BDNNmodel 1 -trait_file data/reptilia/Reptilia_species_traits.txt -qShift data/Time_bins_CrossStage.txt -n 50000000 -s 50000 -se_gibbs -translate -175\n",
    "- ** python ../PyRate/PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -j 1 -fixShift data/Time_bins_ByStages.txt -BDNNmodel 1 -trait_file data/reptilia/Reptilia_species_traits.txt -qShift data/Time_bins_ByStages.txt -n 50000000 -s 50000 -se_gibbs -translate -175\n",
    "    - Removed -mG flag\n",
    "    - Uses Gibbs sampler: -se_gibbs True\n",
    "\n",
    "BDNN run 5: BDNN 3 w/ more generations\n",
    "- python ../PyRate/PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -j 1 -fixShift data/Time_bins_ByStages.txt -BDNNmodel 1 -trait_file data/reptilia/Reptilia_species_traits.txt -qShift data/Time_bins_ByStages.txt -n 200000000 -s 20000 -BDNNnodes 8 4 -translate -175\n",
    "    - Only doing By Stages now, since both By and Cross Stages had similar results, and By Stages makes more conceptual sense\n",
    "    - Run the above 4 x to compare whether each independent run reaches the same values (convergence)\n",
    "\n",
    "COVAR run 2: more gens just to check RJMCMC times of rate shift\n",
    "- python ../PyRate/PyRate.py reptilia/Reptilia_cleaned_pyrate_input_PyRate.py -trait_file data/reptilia/Reptilia_species_traits.txt -mCov 5 -logT 1 -pC 0 -fixShift data/Time_bins_ByStages.txt -qShift data/Time_bins_ByStages.txt -A 4 -n 200000000 -s 20000\n",
    "    - This is: a Covar BD model with fixed times of rate shifts, log transformed traits, TPP and Gamma preservation model, parameter estimation MCMC\n",
    "    - Removed -mG\n",
    "    - Run the above 4 x to compare whether each independent run reaches the same values (convergence\n",
    "\n",
    "\n",
    "NOTE:\n",
    "- Cross Stages from BDNN run 4.b and 4.a (in that orientation) are the only ones currently running as of 9/4!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>it</th>\n",
       "      <th>posterior</th>\n",
       "      <th>prior</th>\n",
       "      <th>PP_lik</th>\n",
       "      <th>BD_lik</th>\n",
       "      <th>q_0</th>\n",
       "      <th>q_1</th>\n",
       "      <th>q_2</th>\n",
       "      <th>q_3</th>\n",
       "      <th>q_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Yelaphomte_TE</th>\n",
       "      <th>Yimenosaurus_TE</th>\n",
       "      <th>Youngetta_TE</th>\n",
       "      <th>Youngina_TE</th>\n",
       "      <th>Youngosuchus_TE</th>\n",
       "      <th>Yunguisaurus_TE</th>\n",
       "      <th>Yunnanosaurus_TE</th>\n",
       "      <th>Zanclodon_TE</th>\n",
       "      <th>Zhongjiania_TE</th>\n",
       "      <th>Zupaysaurus_TE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-19488.475162</td>\n",
       "      <td>-519.246613</td>\n",
       "      <td>-11382.427246</td>\n",
       "      <td>-7586.801303</td>\n",
       "      <td>0.283842</td>\n",
       "      <td>0.283842</td>\n",
       "      <td>0.283842</td>\n",
       "      <td>0.283842</td>\n",
       "      <td>0.283842</td>\n",
       "      <td>...</td>\n",
       "      <td>210.773269</td>\n",
       "      <td>199.882408</td>\n",
       "      <td>247.366545</td>\n",
       "      <td>251.166559</td>\n",
       "      <td>247.083426</td>\n",
       "      <td>237.072325</td>\n",
       "      <td>199.375500</td>\n",
       "      <td>191.859012</td>\n",
       "      <td>255.134883</td>\n",
       "      <td>222.219523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>-15455.251899</td>\n",
       "      <td>-528.505992</td>\n",
       "      <td>-10340.130915</td>\n",
       "      <td>-4586.614992</td>\n",
       "      <td>0.517565</td>\n",
       "      <td>0.428381</td>\n",
       "      <td>0.416735</td>\n",
       "      <td>0.545225</td>\n",
       "      <td>0.394254</td>\n",
       "      <td>...</td>\n",
       "      <td>210.461578</td>\n",
       "      <td>199.579867</td>\n",
       "      <td>247.366545</td>\n",
       "      <td>250.991207</td>\n",
       "      <td>247.083426</td>\n",
       "      <td>237.072325</td>\n",
       "      <td>199.375500</td>\n",
       "      <td>192.214232</td>\n",
       "      <td>255.248001</td>\n",
       "      <td>222.219523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>-15151.722528</td>\n",
       "      <td>-537.285448</td>\n",
       "      <td>-10387.004305</td>\n",
       "      <td>-4227.432776</td>\n",
       "      <td>0.264763</td>\n",
       "      <td>1.172631</td>\n",
       "      <td>0.658385</td>\n",
       "      <td>0.298910</td>\n",
       "      <td>0.709248</td>\n",
       "      <td>...</td>\n",
       "      <td>210.461578</td>\n",
       "      <td>199.362230</td>\n",
       "      <td>247.281448</td>\n",
       "      <td>250.991207</td>\n",
       "      <td>246.858753</td>\n",
       "      <td>237.102069</td>\n",
       "      <td>198.961248</td>\n",
       "      <td>191.736214</td>\n",
       "      <td>255.628004</td>\n",
       "      <td>222.219523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6000</td>\n",
       "      <td>-15143.049096</td>\n",
       "      <td>-543.922940</td>\n",
       "      <td>-10399.280736</td>\n",
       "      <td>-4199.845420</td>\n",
       "      <td>0.599488</td>\n",
       "      <td>1.129137</td>\n",
       "      <td>0.600612</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>0.798106</td>\n",
       "      <td>...</td>\n",
       "      <td>210.461578</td>\n",
       "      <td>199.539161</td>\n",
       "      <td>247.400523</td>\n",
       "      <td>251.372468</td>\n",
       "      <td>246.858753</td>\n",
       "      <td>237.030775</td>\n",
       "      <td>199.055066</td>\n",
       "      <td>191.370345</td>\n",
       "      <td>255.615157</td>\n",
       "      <td>222.016264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8000</td>\n",
       "      <td>-15161.341155</td>\n",
       "      <td>-550.906728</td>\n",
       "      <td>-10443.575200</td>\n",
       "      <td>-4166.859227</td>\n",
       "      <td>0.568970</td>\n",
       "      <td>1.591494</td>\n",
       "      <td>0.669723</td>\n",
       "      <td>0.427113</td>\n",
       "      <td>0.798312</td>\n",
       "      <td>...</td>\n",
       "      <td>210.281404</td>\n",
       "      <td>199.919074</td>\n",
       "      <td>247.350455</td>\n",
       "      <td>252.446115</td>\n",
       "      <td>246.858753</td>\n",
       "      <td>235.938600</td>\n",
       "      <td>199.055066</td>\n",
       "      <td>190.719868</td>\n",
       "      <td>255.615157</td>\n",
       "      <td>222.202844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1872 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     it     posterior       prior        PP_lik       BD_lik       q_0  \\\n",
       "0     0 -19488.475162 -519.246613 -11382.427246 -7586.801303  0.283842   \n",
       "1  2000 -15455.251899 -528.505992 -10340.130915 -4586.614992  0.517565   \n",
       "2  4000 -15151.722528 -537.285448 -10387.004305 -4227.432776  0.264763   \n",
       "3  6000 -15143.049096 -543.922940 -10399.280736 -4199.845420  0.599488   \n",
       "4  8000 -15161.341155 -550.906728 -10443.575200 -4166.859227  0.568970   \n",
       "\n",
       "        q_1       q_2       q_3       q_4  ...  Yelaphomte_TE  \\\n",
       "0  0.283842  0.283842  0.283842  0.283842  ...     210.773269   \n",
       "1  0.428381  0.416735  0.545225  0.394254  ...     210.461578   \n",
       "2  1.172631  0.658385  0.298910  0.709248  ...     210.461578   \n",
       "3  1.129137  0.600612  0.443968  0.798106  ...     210.461578   \n",
       "4  1.591494  0.669723  0.427113  0.798312  ...     210.281404   \n",
       "\n",
       "   Yimenosaurus_TE  Youngetta_TE  Youngina_TE  Youngosuchus_TE  \\\n",
       "0       199.882408    247.366545   251.166559       247.083426   \n",
       "1       199.579867    247.366545   250.991207       247.083426   \n",
       "2       199.362230    247.281448   250.991207       246.858753   \n",
       "3       199.539161    247.400523   251.372468       246.858753   \n",
       "4       199.919074    247.350455   252.446115       246.858753   \n",
       "\n",
       "   Yunguisaurus_TE  Yunnanosaurus_TE  Zanclodon_TE  Zhongjiania_TE  \\\n",
       "0       237.072325        199.375500    191.859012      255.134883   \n",
       "1       237.072325        199.375500    192.214232      255.248001   \n",
       "2       237.102069        198.961248    191.736214      255.628004   \n",
       "3       237.030775        199.055066    191.370345      255.615157   \n",
       "4       235.938600        199.055066    190.719868      255.615157   \n",
       "\n",
       "   Zupaysaurus_TE  \n",
       "0      222.219523  \n",
       "1      222.219523  \n",
       "2      222.219523  \n",
       "3      222.016264  \n",
       "4      222.202844  \n",
       "\n",
       "[5 rows x 1872 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcmc = pd.read_csv('pyrate_mcmc_logs/Reptilia_cleaned_pyrate_input_1_G_BDS_BDNN_16_8Tc_mcmc.log', sep='\\t')\n",
    "mcmc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if any columns are a list\n",
    "list_columns = mcmc.columns[mcmc.applymap(lambda x: isinstance(x, list)).any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing Commands\n",
    "\n",
    "### First Steps:\n",
    "- Move MCMC files into descriptive folder\n",
    "- Check Tracer to decide on burn-in percentage\n",
    "\n",
    "### Marginal RTT Plot\n",
    "**Output in pyrate_mcmc_logs/bdnn...**: _RTT.pdf, _RTT.r\n",
    "BDNN run 3:\n",
    "- *python ../PyRate/PyRate.py -plotBDNN reptilia/pyrate_mcmc_logs/bdnn3_cross/Reptilia_cleaned_pyrate_input_1_BDS_BDNN_8_4Tc_mcmc.log -b 0.15 -translate -175\n",
    "- *python ../PyRate/PyRate.py -plotBDNN reptilia/pyrate_mcmc_logs/bdnn3_by/Reptilia_cleaned_pyrate_input_1_BDS_BDNN_8_4Tc_mcmc.log -b 0.15 -translate -175\n",
    "\n",
    "BDNN run 4 (gibbs):\n",
    "- python ../PyRate/PyRate.py -plotBDNN reptilia/pyrate_mcmc_logs/bdnn4_cross/  _mcmc.log -b 0.1 -translate -175\n",
    "- python ../PyRate/PyRate.py -plotBDNN reptilia/pyrate_mcmc_logs/bdnn4_by/  _mcmc.log -b 0.1 -translate -175\n",
    "\n",
    "### Partial Dependence Plots (PDP)\n",
    "**Output in pyrate_mcmc_logs/bdnn...**: _PDP.pdf, _PDP.r\n",
    "BDNN run 3:\n",
    "- *python ../PyRate/PyRate.py -plotBDNN_effects reptilia/pyrate_mcmc_logs/bdnn3_cross/Reptilia_cleaned_pyrate_input_1_BDS_BDNN_8_4Tc_mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt -translate -175 -b 0.15 -resample 100\n",
    "- *python ../PyRate/PyRate.py -plotBDNN_effects reptilia/pyrate_mcmc_logs/bdnn3_by/Reptilia_cleaned_pyrate_input_1_BDS_BDNN_8_4Tc_mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt -translate -175 -b 0.15 -resample 100\n",
    "\n",
    "BDNN run 4:\n",
    "- python ../PyRate/PyRate.py -plotBDNN_effects reptilia/pyrate_mcmc_logs/bdnn4_cross      mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt\n",
    "python ../PyRate/PyRate.py -plotBDNN_effects reptilia/pyrate_mcmc_logs/bdnn4_by      mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt\n",
    "\n",
    "### Partial Dependence Rates: DEFUNCT\n",
    "*Accourding to Hauffe: only needed if you want n-way interactions where n>3*\n",
    "BDNN run 3:\n",
    "- *python ../PyRate/PyRate.py -BDNN_interaction reptilia/pyrate_mcmc_logs/bdnn3_cross/Reptilia_cleaned_pyrate_input_1_BDS_BDNN_8_4Tc_mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt -b 0.15 -resample 100\n",
    "\n",
    "BDNN run4:\n",
    "- python ../PyRate/PyRate.py -BDNN_interaction reptilia/pyrate_mcmc_logs/bdnn4      mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt -b 0.1 -resample 100\n",
    "\n",
    "### Predictor Importance\n",
    "**Output in pyrate_mcmc_logs/bdnn...**: \n",
    "- _contribution_per_species_rates.r\n",
    "- _contribution_per_species_rates.pdf\n",
    "- ex_predictor_influence.csv\n",
    "- ex_shap_per_species.csv\n",
    "- sp_predictor_influence.csv\n",
    "- sp_shap_per_species.csv\n",
    "\n",
    "BDNN run 3:\n",
    "- *python ../PyRate/PyRate.py -BDNN_pred_importance reptilia/pyrate_mcmc_logs/bdnn3_cross/Reptilia_cleaned_pyrate_input_1_BDS_BDNN_8_4Tc_mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt -b 0.15 -resample 100 -BDNN_nsim_expected_cv 0 -BDNN_pred_importance_interaction\n",
    "    - BDNN_pred_importance: rank 2-way interactions in addition to per-predictor\n",
    "    - Notes from the run: Different bin sizes detected due to using -fixShift. Time windows resampled to a resolution of 5.0. \n",
    "        - (Because CrossStage's smallest bin size is 5)\n",
    "- *python ../PyRate/PyRate.py -BDNN_pred_importance reptilia/pyrate_mcmc_logs/bdnn3_by/Reptilia_cleaned_pyrate_input_1_BDS_BDNN_8_4Tc_mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt -b 0.15 -resample 100 -BDNN_nsim_expected_cv 0 -BDNN_pred_importance_interaction\n",
    "\n",
    "BDNN run 4:\n",
    "- python ../PyRate/PyRate.py -BDNN_pred_importance reptilia/pyrate_mcmc_logs/bdnn4_cross       _mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt -b 0.1 -resample 100 -BDNN_nsim_expected_cv 0 -BDNN_pred_importance_interaction\n",
    "- python ../PyRate/PyRate.py -BDNN_pred_importance reptilia/pyrate_mcmc_logs/bdnn4_by       _mcmc.log -plotBDNN_transf_features data/reptilia/reptilia_backscale.txt -b 0.1 -resample 100 -BDNN_nsim_expected_cv 0 -BDNN_pred_importance_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Code Exploration\n",
    "ex_shap_per_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYRATE CODE\n",
    " elif args.BDNN_pred_importance != \"\":\n",
    "        import pyrate_lib.bdnn_lib as bdnn_lib\n",
    "        path_dir_log_files = args.BDNN_pred_importance.replace(\"_mcmc.log\", \"\")\n",
    "        pkl_file = path_dir_log_files + \".pkl\"\n",
    "        mcmc_file = path_dir_log_files + \"_mcmc.log\"\n",
    "        do_inter_imp = args.BDNN_pred_importance_interaction is False\n",
    "        BDNNmodel = bdnn_lib.get_bdnn_model(pkl_file)\n",
    "        sp_taxa_shap, ex_taxa_shap, q_taxa_shap = None, None, None\n",
    "        sp_main_consrank, ex_main_consrank, q_main_consrank = None, None, None\n",
    "        if BDNNmodel in [1, 3] and args.BDNN_nsim_expected_cv > 0:\n",
    "            print(\"Getting expected coefficient of rate variation\")\n",
    "            bdnn_lib.get_coefficient_rate_variation(path_dir_log_files, burnin,\n",
    "                                                    combine_discr_features=args.BDNN_groups,\n",
    "                                                    num_sim=args.BDNN_nsim_expected_cv,\n",
    "                                                    num_processes=args.thread[0],\n",
    "                                                    show_progressbar=True)\n",
    "        if BDNNmodel in [2, 3] and args.BDNN_nsim_expected_cv > 0:\n",
    "            print(\"Getting expected coefficient of sampling variation\")\n",
    "            bdnn_lib.get_coefficient_sampling_variation(path_dir_log_files, burnin,\n",
    "                                                        combine_discr_features=args.BDNN_groups,\n",
    "                                                        num_sim=args.BDNN_nsim_expected_cv,\n",
    "                                                        num_processes=args.thread[0],\n",
    "                                                        show_progressbar=True)\n",
    "        if BDNNmodel in [1, 3]:\n",
    "            print(\"Getting permutation importance birth-death\")\n",
    "            sp_featperm, ex_featperm = bdnn_lib.feature_permutation(mcmc_file, pkl_file,\n",
    "                                                                    burnin,\n",
    "                                                                    thin=args.resample,\n",
    "                                                                    min_bs=args.BDNN_pred_importance_window_size[0],\n",
    "                                                                    n_perm=args.BDNN_pred_importance_nperm,\n",
    "                                                                    num_processes=args.thread[0],\n",
    "                                                                    combine_discr_features=args.BDNN_groups,\n",
    "                                                                    show_progressbar=True,\n",
    "                                                                    do_inter_imp=do_inter_imp)\n",
    "        if BDNNmodel in [2, 3]:\n",
    "            print(\"Getting permutation importance sampling\")\n",
    "            q_featperm = bdnn_lib.feature_permutation_sampling(mcmc_file, pkl_file,\n",
    "                                                               burnin,\n",
    "                                                               thin=args.resample,\n",
    "                                                               min_bs=args.BDNN_pred_importance_window_size[-1],\n",
    "                                                               n_perm=args.BDNN_pred_importance_nperm,\n",
    "                                                               num_processes=args.thread[0],\n",
    "                                                               combine_discr_features= args.BDNN_groups,\n",
    "                                                               show_progressbar=True,\n",
    "                                                               do_inter_imp=do_inter_imp)\n",
    "        if BDNNmodel in [1, 3]:\n",
    "            print(\"Getting SHAP values birth-death\")\n",
    "            sp_shap, ex_shap, sp_taxa_shap, ex_taxa_shap = bdnn_lib.k_add_kernel_shap(mcmc_file, pkl_file,\n",
    "                                                                                      burnin,\n",
    "                                                                                      thin=args.resample,\n",
    "                                                                                      num_processes=args.thread[0],\n",
    "                                                                                      combine_discr_features=args.BDNN_groups,\n",
    "                                                                                      show_progressbar=True,\n",
    "                                                                                      do_inter_imp=do_inter_imp,\n",
    "                                                                                      use_mean=args.BDNN_mean_shap_per_group)\n",
    "        if BDNNmodel in [2, 3]:\n",
    "            print(\"Getting SHAP values sampling\")\n",
    "            q_shap, q_taxa_shap = bdnn_lib.k_add_kernel_shap_sampling(mcmc_file, pkl_file,\n",
    "                                                                      burnin,\n",
    "                                                                      thin=args.resample,\n",
    "                                                                      num_processes=args.thread[0],\n",
    "                                                                      combine_discr_features=args.BDNN_groups,\n",
    "                                                                      show_progressbar=True,\n",
    "                                                                      do_inter_imp=do_inter_imp)\n",
    "        obj_effect = bdnn_lib.get_effect_objects(mcmc_file, pkl_file,\n",
    "                                                 burnin,\n",
    "                                                 thin=args.resample,\n",
    "                                                 combine_discr_features=args.BDNN_groups,\n",
    "                                                 file_transf_features=args.plotBDNN_transf_features,\n",
    "                                                 num_processes=args.thread[0],\n",
    "                                                 show_progressbar=True,\n",
    "                                                 do_inter_imp=do_inter_imp)\n",
    "        bdnn_obj, cond_trait_tbl_sp, cond_trait_tbl_ex, cond_trait_tbl_q, names_features_sp, names_features_ex, names_features_q, sp_rate_part, ex_rate_part, q_rate_part, sp_fad_lad, backscale_par = obj_effect\n",
    "        if BDNNmodel in [1, 3]:\n",
    "            print(\"Getting marginal probabilities birth-death\")\n",
    "            sp_pv = bdnn_lib.get_prob_effects(cond_trait_tbl_sp, sp_rate_part, bdnn_obj, names_features_sp, rate_type='speciation')\n",
    "            ex_pv = bdnn_lib.get_prob_effects(cond_trait_tbl_ex, ex_rate_part, bdnn_obj, names_features_ex, rate_type='extinction')\n",
    "        if BDNNmodel in [2, 3]:\n",
    "            print(\"Getting marginal probabilities sampling\")\n",
    "            q_pv = bdnn_lib.get_prob_effects(cond_trait_tbl_q, q_rate_part, bdnn_obj, names_features_q, rate_type='sampling')\n",
    "        if BDNNmodel in [1, 3]:\n",
    "            # consensus among 3 feature importance methods\n",
    "            print(\"Getting consensus ranking birth-death\")\n",
    "            sp_feat_importance, sp_main_consrank = bdnn_lib.get_consensus_ranking(sp_pv, sp_shap, sp_featperm)\n",
    "            ex_feat_importance, ex_main_consrank = bdnn_lib.get_consensus_ranking(ex_pv, ex_shap, ex_featperm)\n",
    "            output_wd = os.path.dirname(os.path.realpath(path_dir_log_files))\n",
    "            name_file = os.path.basename(path_dir_log_files)\n",
    "            ex_feat_merged_file = os.path.join(output_wd, name_file + '_ex_predictor_influence.csv')\n",
    "            ex_feat_importance.to_csv(ex_feat_merged_file, na_rep='NA', index=False)\n",
    "            sp_feat_merged_file = os.path.join(output_wd, name_file + '_sp_predictor_influence.csv')\n",
    "            sp_feat_importance.to_csv(sp_feat_merged_file, na_rep='NA', index=False)\n",
    "            sp_taxa_shap_file = os.path.join(output_wd, name_file + '_sp_shap_per_species.csv')\n",
    "            sp_taxa_shap.to_csv(sp_taxa_shap_file, na_rep='NA', index=False)\n",
    "            ex_taxa_shap_file = os.path.join(output_wd, name_file + '_ex_shap_per_species.csv')\n",
    "            ex_taxa_shap.to_csv(ex_taxa_shap_file, na_rep='NA', index=False)\n",
    "        if BDNNmodel in [2, 3]:\n",
    "            print(\"Getting consensus ranking sampling\")\n",
    "            q_feat_importance, q_main_consrank = bdnn_lib.get_consensus_ranking(q_pv, q_shap, q_featperm)\n",
    "            output_wd = os.path.dirname(os.path.realpath(path_dir_log_files))\n",
    "            name_file = os.path.basename(path_dir_log_files)\n",
    "            q_feat_merged_file = os.path.join(output_wd, name_file + '_q_predictor_influence.csv')\n",
    "            q_feat_importance.to_csv(q_feat_merged_file, na_rep='NA', index=False)\n",
    "            q_taxa_shap_file = os.path.join(output_wd, name_file + '_q_shap_per_species.csv')\n",
    "            q_taxa_shap.to_csv(q_taxa_shap_file, na_rep='NA', index=False)\n",
    "        # Plot contribution to species-specific rates\n",
    "        bdnn_lib.dotplot_species_shap(mcmc_file, pkl_file, burnin, args.resample, output_wd, name_file,\n",
    "                                      sp_taxa_shap, ex_taxa_shap, q_taxa_shap,\n",
    "                                      sp_main_consrank, ex_main_consrank, q_main_consrank,\n",
    "                                      combine_discr_features=args.BDNN_groups,\n",
    "                                      file_transf_features=args.plotBDNN_transf_features,\n",
    "                                      translate=args.translate)\n",
    "        quit()\n",
    "# Saving Files\n",
    "if BDNNmodel in [1, 3]:\n",
    "            # consensus among 3 feature importance methods\n",
    "            print(\"Getting consensus ranking birth-death\")\n",
    "            sp_feat_importance, sp_main_consrank = bdnn_lib.get_consensus_ranking(sp_pv, sp_shap, sp_featperm)\n",
    "            ex_feat_importance, ex_main_consrank = bdnn_lib.get_consensus_ranking(ex_pv, ex_shap, ex_featperm)\n",
    "            output_wd = os.path.dirname(os.path.realpath(path_dir_log_files))\n",
    "            name_file = os.path.basename(path_dir_log_files)\n",
    "            ex_feat_merged_file = os.path.join(output_wd, name_file + '_ex_predictor_influence.csv')\n",
    "            ex_feat_importance.to_csv(ex_feat_merged_file, na_rep='NA', index=False)\n",
    "            sp_feat_merged_file = os.path.join(output_wd, name_file + '_sp_predictor_influence.csv')\n",
    "            sp_feat_importance.to_csv(sp_feat_merged_file, na_rep='NA', index=False)\n",
    "            sp_taxa_shap_file = os.path.join(output_wd, name_file + '_sp_shap_per_species.csv')\n",
    "            sp_taxa_shap.to_csv(sp_taxa_shap_file, na_rep='NA', index=False)\n",
    "            ex_taxa_shap_file = os.path.join(output_wd, name_file + '_ex_shap_per_species.csv')\n",
    "            ex_taxa_shap.to_csv(ex_taxa_shap_file, na_rep='NA', index=False)\n",
    "\n",
    "\n",
    "# BDNN_LIB CODE\n",
    "def k_add_kernel_shap(mcmc_file, pkl_file, burnin, thin, num_processes=1, combine_discr_features={}, show_progressbar=False, do_inter_imp=True, use_mean=False):\n",
    "#    if do_inter_imp == False:\n",
    "#        from fastshap import KernelExplainer\n",
    "    bdnn_obj, post_w_sp, post_w_ex, _, sp_fad_lad, post_ts, post_te, post_t_reg_lam, post_t_reg_mu, _, post_reg_denom_lam, post_reg_denom_mu, _, _, _ = bdnn_parse_results(mcmc_file, pkl_file, burnin, thin)\n",
    "    mcmc_samples = post_ts.shape[0]\n",
    "    trt_tbls = bdnn_obj.trait_tbls[:2]\n",
    "    n_species = trt_tbls[0].shape[-2]\n",
    "    n_features = trt_tbls[0].shape[-1]\n",
    "    names_features_sp = get_names_features(bdnn_obj, rate_type='speciation')\n",
    "    names_features_ex = copy_lib.deepcopy(names_features_sp)\n",
    "    n_states = 1\n",
    "    if len(combine_discr_features) > 0:\n",
    "        n_states = len(combine_discr_features[list(combine_discr_features.keys())[0]])\n",
    "#    if n_features == 1 or (n_states == n_features):\n",
    "#        return make_shap_result_for_single_feature(names_features_sp, names_features_ex, combine_discr_features)\n",
    "    if n_features == 1:\n",
    "        if n_states > n_features:\n",
    "            do_inter_imp = False\n",
    "        else:\n",
    "            return make_shap_result_for_single_feature(names_features_sp, names_features_ex, combine_discr_features)\n",
    "    bdnn_dd = 'diversity' in names_features_sp\n",
    "    div_idx_trt_tbl = -1\n",
    "    if is_time_trait(bdnn_obj) and bdnn_dd:\n",
    "            div_idx_trt_tbl = -2\n",
    "    hidden_act_f = bdnn_obj.bdnn_settings['hidden_act_f']\n",
    "    out_act_f = bdnn_obj.bdnn_settings['out_act_f']\n",
    "    idx_comb_feat_sp = get_idx_comb_feat(names_features_sp, combine_discr_features)\n",
    "    idx_comb_feat_ex = get_idx_comb_feat(names_features_ex, combine_discr_features)\n",
    "    shap_names_sp = make_shap_names(names_features_sp, idx_comb_feat_sp, combine_discr_features, do_inter_imp = do_inter_imp)\n",
    "    shap_names_ex = make_shap_names(names_features_ex, idx_comb_feat_ex, combine_discr_features, do_inter_imp = do_inter_imp)\n",
    "    n_main_eff_sp = np.sum(shap_names_sp[:, 1] == 'none')\n",
    "    n_main_eff_ex = np.sum(shap_names_ex[:, 1] == 'none')\n",
    "    n_inter_eff_sp = int(n_main_eff_sp * (n_main_eff_sp - 1) / 2)\n",
    "    n_inter_eff_ex = int(n_main_eff_sp * (n_main_eff_sp - 1) / 2)\n",
    "    if do_inter_imp is False:\n",
    "        n_inter_eff_sp = 0\n",
    "        n_inter_eff_ex = 0\n",
    "    n_effects_sp = n_main_eff_sp + n_inter_eff_sp + 1 + n_species * n_main_eff_sp # np.concatenate((shap_main, shap_interaction, baseline, shap_main_instances.flatten()))\n",
    "    n_effects_ex = n_main_eff_ex + n_inter_eff_ex + 1 + n_species * n_main_eff_ex\n",
    "    args = []\n",
    "    for i in range(mcmc_samples):\n",
    "        a = [bdnn_obj, post_ts[i, :], post_te[i, :],\n",
    "             post_w_sp[i], post_w_ex[i], post_t_reg_lam[i], post_t_reg_mu[i], post_reg_denom_lam[i], post_reg_denom_mu[i],\n",
    "             hidden_act_f, out_act_f, trt_tbls, bdnn_dd, div_idx_trt_tbl, idx_comb_feat_sp, idx_comb_feat_ex, do_inter_imp, use_mean]\n",
    "        args.append(a)\n",
    "    unixos = is_unix()\n",
    "    if unixos and num_processes > 1:\n",
    "        pool_perm = multiprocessing.Pool(num_processes)\n",
    "        shap_values = list(tqdm(pool_perm.imap_unordered(k_add_kernel_shap_i, args),\n",
    "                                total = mcmc_samples, disable = show_progressbar == False))\n",
    "        pool_perm.close()\n",
    "    else:\n",
    "        shap_values = []\n",
    "        for i in tqdm(range(mcmc_samples), disable = show_progressbar == False):\n",
    "            shap_values.append(k_add_kernel_shap_i(args[i]))\n",
    "    shap_values = np.vstack(shap_values)\n",
    "    shap_summary = get_rates_summary(shap_values.T)\n",
    "    mean_shap_sp = shap_summary[:(n_main_eff_sp + n_inter_eff_sp), :]\n",
    "    mean_shap_ex = shap_summary[n_effects_sp:(n_effects_sp + n_main_eff_ex + n_inter_eff_ex), :]\n",
    "    taxa_shap_sp = shap_summary[(n_main_eff_sp + n_inter_eff_sp):n_effects_sp, :] # First row is baseline\n",
    "    taxa_shap_ex = shap_summary[(n_effects_sp + n_main_eff_ex + n_inter_eff_ex):, :]\n",
    "    if bdnn_dd:\n",
    "        trt_tbls[0][0, :, div_idx_trt_tbl] = 1.0\n",
    "        trt_tbls[1][0, :, div_idx_trt_tbl] = 1.0\n",
    "    feature_without_variance_sp = get_idx_feature_without_variance(trt_tbls[0])\n",
    "    feature_without_variance_ex = get_idx_feature_without_variance(trt_tbls[1])\n",
    "    remove_sp = []\n",
    "    for i in feature_without_variance_sp:\n",
    "        remove_sp.append(np.where(shap_names_sp[:, 0] == names_features_sp[i])[0])\n",
    "        remove_sp.append(np.where(shap_names_sp[:, 1] == names_features_sp[i])[0])\n",
    "    remove_ex = []\n",
    "    for i in feature_without_variance_ex:\n",
    "        remove_ex.append(np.where(shap_names_ex[:, 0] == names_features_ex[i])[0])\n",
    "        remove_ex.append(np.where(shap_names_ex[:, 1] == names_features_ex[i])[0])\n",
    "    remove_sp = np.array(list(pd.core.common.flatten(remove_sp))).astype(int)\n",
    "    remove_ex = np.array(list(pd.core.common.flatten(remove_ex))).astype(int)\n",
    "    mean_shap_sp = np.delete(mean_shap_sp, remove_sp[remove_sp < len(mean_shap_sp)], axis = 0)\n",
    "    mean_shap_ex = np.delete(mean_shap_ex, remove_ex[remove_ex < len(mean_shap_ex)], axis = 0)\n",
    "    shap_names_sp_del = np.delete(shap_names_sp, remove_sp, axis = 0)\n",
    "    shap_names_ex_del = np.delete(shap_names_ex, remove_ex, axis = 0)\n",
    "    shap_values_sp = pd.DataFrame(mean_shap_sp, columns = ['shap', 'lwr_shap', 'upr_shap'])\n",
    "    shap_values_ex = pd.DataFrame(mean_shap_ex, columns = ['shap', 'lwr_shap', 'upr_shap'])\n",
    "    shap_names_sp_del = pd.DataFrame(shap_names_sp_del, columns = ['feature1', 'feature2'])\n",
    "    shap_names_ex_del = pd.DataFrame(shap_names_ex_del, columns = ['feature1', 'feature2'])\n",
    "    shap_lam = pd.concat([shap_names_sp_del, shap_values_sp], axis = 1)\n",
    "    shap_ex = pd.concat([shap_names_ex_del, shap_values_ex], axis = 1)\n",
    "    taxa_names = sp_fad_lad[\"Taxon\"]\n",
    "    taxa_names_shap_sp = make_taxa_names_shap(taxa_names, n_species, shap_names_sp_del)\n",
    "    taxa_names_shap_ex = make_taxa_names_shap(taxa_names, n_species, shap_names_ex_del)\n",
    "    taxa_shap_sp = delete_invariantfeat_from_taxa_shap(feature_without_variance_sp, names_features_sp,\n",
    "                                                       shap_names_sp, taxa_shap_sp)\n",
    "    taxa_shap_ex = delete_invariantfeat_from_taxa_shap(feature_without_variance_ex, names_features_ex,\n",
    "                                                       shap_names_ex, taxa_shap_ex)\n",
    "    sp_from_shap = get_species_rates_from_shap(shap_values[:, (n_main_eff_sp + n_inter_eff_sp):n_effects_sp],\n",
    "                                               n_species, n_main_eff_sp, mcmc_samples)\n",
    "    ex_from_shap = get_species_rates_from_shap(shap_values[:, (n_effects_sp + n_main_eff_ex + n_inter_eff_ex):],\n",
    "                                               n_species, n_main_eff_ex, mcmc_samples)\n",
    "    taxa_shap_sp = merge_taxa_shap_and_species_rates(taxa_shap_sp, taxa_names_shap_sp, sp_from_shap, n_species)\n",
    "    taxa_shap_ex = merge_taxa_shap_and_species_rates(taxa_shap_ex, taxa_names_shap_ex, ex_from_shap, n_species)\n",
    "    return shap_lam, shap_ex, taxa_shap_sp, taxa_shap_ex\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
